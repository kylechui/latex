\documentclass[class=article, crop=false]{standalone}
\input{/Users/kylec/github/latex/Preamble}

\fancyhf{}
\lhead{\leftmark}
\rhead{Page \thepage}
\pagestyle{fancy}

\begin{document}
  \begin{theorem}{Subspace Theorem}
    Let $V$ be a vector space over $F$, $\es\neq W\sse V$ a subset. Then the following are equivalent:
    \begin{enumerate}[label=(\alph*)]
      \item $W$ is a subspace of $V$
      \item $W$ is closed under addition and scalar multiplication from $V$
      \item For all $w_1,w_2\in W$, for all $\alpha\in F$, $\alpha w_1+w_2\in W$
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    (a $\Rightarrow$ b) This holds by definition. \\[10pt]
    (b $\Rightarrow$ a) We claim that $0_V\in W$ and $0_W = 0_V$. Because $W$ is non-empty, there exists $w\in W$. Because $W$ is closed under scalar multiplication, $(-1)w\in W$, so $0_V = w + (-w) \in W$. Furthermore, for all $w'\in W$, we have that $0_V + w' = w' = w' + 0_V$, so $0_V = 0_W$. \\[10pt]
    (b $\Rightarrow$ c) Because $W$ is closed under multiplication, we have that for all $w_1\in W$ and $\alpha\in F$, $\alpha w_1\in W$. Furthermore, because $W$ is closed under addition, $\alpha w_1 + w_2\in W$ for all $w_2\in W$. \\[10pt]
    (c $\Rightarrow$ b) If we let $\alpha = 0$, we have closure under addition. If we let $w_2 = 0$, we have closure under multiplication.
  \end{proof}
  \newpage
  \begin{theorem}{Toss In Theorem}
    Let $V$ be a vector space over $F$, $\es\neq S\sse V$ a linearly independent subset. Suppose that $v\in V\sm \vspan(S)$. Then $S\cup \set{v}$ is linearly independent.
  \end{theorem}
  \begin{proof}
    Suppose towards a contradiction that $S\cup \set{v}$ is linearly dependent. In other words, there exists a subset $\set{v_1,\dotsc,v_n}\sse S$ such that for some $\alpha_1,\dotsc,\alpha_{n+1}\in F$, not all zero, such that
    \[
      \alpha_1v_1 + \dotsb + \alpha_nv_n + \alpha_{n+1}v = 0.
    \]
    We know that $\alpha_{n+1}\neq 0$ because otherwise we would have $\alpha_1v_1 + \dotsb + \alpha_nv_n = 0$, where not all $\alpha_i = 0$, which contradicts that $S$ is a linearly independent subset. Since $\alpha_{n+1} \neq 0$, it has an inverse. Thus we may write
    \[
      v = -\frac{\alpha_1}{\alpha_{n+1}}v_1 - \dotsb - \frac{\alpha_n}{\alpha_{n+1}}v_n,
    \]
    so $v\in \vspan(S)$. Thus we have arrived at the contradiction that $v$ is both in the span of $S$ and also not in the span of $S$.
  \end{proof}
  \newpage
  \begin{theorem}{Coordinate Theorem}
    Let $V$ be a finite-dimensional vector space over $F$ with basis $\mathcal{B} = \set{v_1,\dotsc,v_n}$ and $v\in V$. Then there exists unique $\alpha_1,\dotsc,\alpha_n\in F$ such that
    \[
      v = \alpha_1v_1 + \dotsb + \alpha_nv_n.
    \]
    We call $\alpha_1,\dotsc,\alpha_n$ the \emph{coordinates} of $v$ relative to the basis $\mathcal{B}$ and call $\alpha_i$ the $i$th coordinate relative to $\mathcal{B}$.
  \end{theorem}
  \begin{proof}
    Because $\mathcal{B}$ is a basis for $V$, we know that $\mathcal{B}$, so all vectors $v\in V$ may be written as a linear combination of the basis vectors. We must show that this representation is unique. Let $v\in V$ and $\alpha_i, \beta_i\in F$, for $i = 1,\dotsc,n$. Then
    \[
      \beta_1v_1 + \dotsb + \beta_nv_n = v = \alpha_1v_1 + \dotsb + \alpha_nv_n.
    \]
    Moving things to one side, we have
    \[
      (\alpha_1-\beta_1)v_1 + \dotsb + (\alpha_n-\beta_n)v_n = 0.
    \]
    Because $\mathcal{B}$ is a basis and thus linearly independent, we have that $\alpha_i = \beta_i$ for all $i = 1,\dotsc,n$, so the representation is unique.
  \end{proof}
  \newpage
  \begin{theorem}{Important Exercise (General Toss Out Theorem)}
    Let $V$ be a vector space over $F$, with $v_1,\dotsc,v_n\in V$. Then
    \[
      \vspan(v_1,\dotsc,v_n) = \vspan(v_2,\dotsc,v_n)
    \]
    if and only if $v_1\in \vspan(v_2,\dotsc,v_n)$.
  \end{theorem}
  \begin{proof}
    ($\Rightarrow$) Suppose $\vspan(v_1,\dotsc,v_n) = \vspan(v_2,\dotsc,v_n)$. Then for all $\alpha_1,\dotsc,\alpha_n\in F$, there exist $\beta_2,\dotsc,\beta_n$ such that
    \[
      \alpha_1v_1 + \dotsb + \alpha_nv_n = \beta_2v_2 + \dotsb + \beta_nv_n.
    \]
    Because this equality must hold for all $\alpha_i$, we may assume that $\alpha_1\neq 0$. Thus 
    \begin{align*}
      \alpha_1v_1 &= (\beta_2-\alpha_2)v_2 + \dotsb + (\beta_n-\alpha_n)v_n \\
      v_1 &= \alpha_1\inv(\beta_2-\alpha_2)v_2 + \dotsb + \alpha_1\inv(\beta_n-\alpha_n)v_n,
    \end{align*}
    so $v_1\in \vspan(v_2,\dotsc,v_n)$. \\[10pt]
    ($\Leftarrow$) Let $v_1 \in \vspan(v_2,\dotsc,v_n)$, so $v_1 = \alpha_2v_2 + \dotsb + \alpha_nv_n$ for $\alpha_i\in F$ for $i = 2,\dotsc,n$. Then 
    \begin{align*}
      \vspan(v_1,\dotsc,v_n) &= \beta_1v_1 + \dotsb + \beta_nv_n \\
                             &= \beta_1(\alpha_2v_2 + \dotsb + \alpha_nv_n) + \beta_nv_n \\
                             &= (\beta_1\alpha_2 + \beta_2)v_2 + \dotsb + (\beta_1\alpha_n + \beta_n)v_n \\
                             &= \vspan(v_2,\dotsc,v_n).
    \end{align*}
  \end{proof}
  \newpage
  \begin{theorem}{Toss Out Theorem}
    Let $V$ be a vector space over $F$. If $V$ can be spanned by finitely many vectors then $V$ is a finite-dimensional vector space over $F$. More precisely, if 
    \[
      V = \vspan(v_1,\dotsc,v_n),
    \]
    then a subset of $\set{v_1,\dotsc,v_n}$ is a basis for $V$.
  \end{theorem}
  \begin{proof}
    If $V = 0$, there is nothing to prove, so we may assume that $V$ is non-zero. Suppose that $V = \vspan(v_1,\dotsc,v_n)$. We prove by induction on $n$ that a subset of $\set{v_1,\dotsc,v_n}$ is a basis. When $n = 1$, we have $V = \vspan(v_1)\neq 0$ and because $V \neq 0$, we know $v_1\neq 0$. Thus $\set{v_1}$ is linearly independent and spans $V$, and so is a basis. Suppose that the statement holds for some $n = k$. We claim that a subset of $\set{v_1,\dotsc,v_{k+1}}$ is a basis for $V$. If $\set{v_1,\dotsc,v_{k+1}}$ is linearly independent, then it is a basis for $V$ because it spans $V$, and we are one. If it is not linearly independent, there exists some vector that is in the span of the other vectors. Without loss of generality, say that $v_{k+1}\in \vspan(v_1,\dotsc,v_k)$. Then we have that $\vspan(v_1,\dotsc,v_k) = \vspan(v_1,\dotsc,v_{k+1})$, so we may remove $v_{k+1}$ from the set while still spanning $V$. By the induction hypothesis, because $\vspan(\set{v_1,\dotsc,v_k}) = V$, a subset of $\set{v_1,\dotsc,v_k}$ is a basis for $V$, so we are done.
  \end{proof}
  \newpage
  \begin{theorem}{Replacement Theorem}
    Let $V$ be a vector space over $F$, with $\set{v_1,\dotsc,v_n}$ a basis for $V$. Suppose that $v\in V$ satisfies
    \[
      v = \alpha_1v_1 + \dotsb + \alpha_nv_n, \tag{$\alpha_1,\dotsc,\alpha_n\in F, \alpha_i\neq 0$}
    \]
    Then
    \[
      \set{v_1,\dotsc,v_{i-1},v,v_{i+1},\dotsc,v_n}
    \]
    is also a basis for $V$.
  \end{theorem}
  \begin{proof}
    Notice that $v\in \vspan(v_1,\dotsc,v_n)$, so $\vspan(v_1,\dotsc,v_n) = \vspan(v_1,\dotsc,v_n,v) = V$ by the General Toss out Theorem. Furthermore, because $\alpha_i\neq 0$, we may rewrite the definition of $v$ as follows:
    \begin{align*}
      v &= \alpha_1v_1 + \dotsb + \alpha_nv_n \\
      \alpha_iv_i &= v - \paren{\sum_{\substack{j=1\\j\neq i}}^{n}\alpha_jv_j} \\
      v_i &= \alpha_i\inv v - \paren{\sum_{\substack{j=1\\j\neq i}}^{n}\alpha_i\inv\alpha_jv_j}
    \end{align*}
    Thus we see that $v_i\in \vspan(v_1,\dotsc,v_{i-1},v,v_{i+1},\dotsc,v_n)$ so 
    \[
      V = \vspan(v_1,\dotsc,v_n, v) = \vspan(v_1,\dotsc,v_{i-1},v,v_{i+1},\dotsc,v_n).
    \]
    Thus it remains to show that this set of vectors is linearly independent. Suppose towards a contradiction that they are linearly dependent, that is there exist $\beta_1,\dotsc,\beta_n\in F$, not all zero, such that
    \[
      \beta_1v_1 + \dotsb + \beta_{i-1}v_{i-1} + \beta_iv + \beta_{i+1}v_{i+1} + \dotsb + \beta_nv_n = 0.
    \]
    If $\beta_i = 0$, then we reach a contradiction because $\set{v_1,\dotsc,v_{i-1},v_{i+1},\dotsc,v_n}$ is a linearly independent set so all $\beta_j$ must be zero. If $\beta_i\neq 0$, then it has an inverse. Thus
    \[
      v = -\beta_i\inv \paren{\beta_1v_1 + \dotsb + \beta_{i-1}v_{i-1} + \beta_{i+1}v_{i+1} + \dotsb + \beta_nv_n}.
    \]
    Moving the terms to one side and expanding, we have
    \[
      0 = \paren{\sum_{\substack{j=1\\j\neq i}}^{n}\paren{\beta_i\inv\beta_j + \alpha_j}v_j} + \alpha_iv_i.
    \]
    Because $\set{v_1,\dotsc,v_n}$ is linearly independent, we know that $\alpha_i = 0$, a contradiction. Therefore we have that $\set{v_1,\dotsc,v_{i-1},v,v_{i+1},\dotsc,v_n}$ is a basis for $V$.
  \end{proof}
  \newpage
  \begin{theorem}{Main Theorem}
    Suppose $V$ is a vector space over $F$ with $V = \vspan(v_1,\dotsc,v_n)$. Then any linearly independent subset of $V$ has at most $n$ elements.
  \end{theorem}
  \begin{proof}
    By the Toss Out Theorem, we know that a subset of $\set{v_1,\dotsc,v_n}$ is a basis for $V$, so we may assume that $\set{v_1,\dotsc,v_n}$ is a basis for $V$. Suppose there is another linearly independent subset of $V$ that has $m$ elements, say $\set{w_1,\dotsc,w_m}$. We proceed via induction. \par
    We claim that after changing notation, if necessary, for each $k\leq n$ that
    \[
      \set{w_1,\dotsc,w_k, v_{k+1},\dotsc,v_n}
    \]
    is a basis for $V$. Applying this claim to $k = n$, we get that $\set{w_1,\dotsc,w_{n+1}}$ is linearly dependent, a contradiction as $\set{w_1,\dotsc,w_n}$ is a basis. Thus we may assume that $k\leq n$. For $k = 1$, we have that $w_1\in \vspan(v_1,\dotsc,v_n)$, so for some $\alpha_i\in F$, not all zero, $i = 1,\dotsc,n$,
    \[
      w_1 = \alpha_1v_1 + \dotsb + \alpha_nv_n.
    \]
    Rearranging if necessary, we may assume that $\alpha_1\neq 0$. Thus by the Replacement Theorem $\set{w_1,\dotsc,v_n}$ is a basis for $V$. Suppose the statement holds for some $n = k$, so $\set{w_1,\dotsc,w_k,v_{k+1},\dotsc,v_n}$ is a basis for $V$. Because $w_{k+1}\in V$, for some $\alpha_i\in F$, not all zero, we have
    \[
      w_{k+1} = \alpha_1w_1 + \dotsb + \alpha_kw_k + \alpha_{k+1}v_{k+1} + \dotsb +  \alpha_nv_n.
    \]
    We know that at least one of the $\alpha_i \neq 0$ for $i \geq k+1$, otherwise we would have that $w_k+1\in \vspan(w_1,\dotsc,w_k)$, a contradiction because the $w_i$'s are linearly independent. Thus rearranging if necessary, we may assume that $\alpha_{k+1}\neq 0$. Therefore we may use the Replacement Theorem, and $\set{w_1,\dotsc,w_{k+1},v_{k+2},\dotsc,v_n}$ is a basis for $V$. Thus the claim has been proven by induction.
  \end{proof}
  \newpage
  \begin{theorem}{Extension Theorem}
    Let $V$ be a finite-dimensional vector space over $F$, $W\sse V$ a subspace. Then every linearly independent subset $S$ in $W$ is finite and part of a basis for $W$ which is a finite-dimensional vector space over $F$.
  \end{theorem}
  \begin{proof}
    We know that $V$ is finite-dimensional, so it must have a finite basis that spans $V$, say $\set{v_1,\dotsc,v_n}$. Thus by the Main Theorem, we know every linearly independent subset must have less than $n$ vectors, and so is finite. We now show that $S$ is a part of a basis for $W$. If $S$ does not span $W$, then there exist vectors that are in $W$ but not in $\vspan(S)$. Thus we may use Toss In Theorem to repeatedly add vectors to $S$ until it spans $W$, at which point it becomes a basis for $W$.
  \end{proof}
  \newpage
  \begin{theorem}{Counting Theorem}
    Let $V$ be a vector space over $F$, with $W_1,W_2\sse V$ subspaces. Suppose that both $W_1$ and $W_2$ are finite-dimensional vector spaces over $F$. Then
    \begin{enumerate}[label=(\alph*)]
      \item $W_1\cap W_2$ is a finite-dimensional vector space over $F$.
      \item $W_1 + W_2$ is a finite-dimensional vector space over $F$.
      \item $\dim(W_1) + \dim(W_2) = \dim(W_1 + W_2) + \dim(W_1\cap W_2)$.
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    We know that $W_1\cap W_2$ is a subspace because it is closed under the same addition and scalar multiplication operations that $W_1$ and $W_2$ are closed under. In other words, for all $v, w\in W_1\cap W_2$ and $\alpha\in F$, we have that
    \[
      \alpha v + w\in W_1 \text{ and } \alpha v + w\in W_2,
    \]
    so $\alpha v + w\in W_1\cap W_2$. Similarly, if $v, w\in W_1 + W_2$, then $\alpha v + w\in W_1 + W_2$ (write each as a linear combo), so $W_1 + W_2$ is a finite-dimensional vector space over $F$. Let $\set{w_1,\dotsc,w_m}$ be a basis for $W_1\cap W_2$. By the Extension Theorem, we may extend it into bases for $W_1$ and $W_2$, say $\mathcal{B} = \set{w_1,\dotsc,w_m,u_{m+1},\dotsc,u_n}$ and $\mathcal{C} = \set{w_1,\dotsc,w_m,v_{m+1},\dotsc,v_\ell}$, respectively. Then we know that $W_1 + W_2$ is spanned by $\mathcal{B}\cup \mathcal{C}$, which has dimension $n + \ell - m$. Notice that this directly yields $\dim(W_1) + \dim(W_2) = \dim(W_1 + W_2) + \dim(W_1\cap W_2)$.
  \end{proof}
  \newpage
  \begin{theorem}{Rank-Nullity (Dimension) Theorem}
    Let $V$ and $W$ be vector spaces over a field $F$, and let $V$ be finite-dimensional. Let $T\colon V\to W$ be a linear transformation. Then $\im(T)$ and $\ker(T)$ are finite-dimensional vector spaces over $F$, and $\dim(V) = \dim(\ker(T)) + \dim(\im(T))$.
  \end{theorem}
  \begin{proof}
    
  \end{proof}
  \begin{theorem}{Monomorphism Theorem}
    Let $T\colon V\to W$ be a linear transformation. Then the following are equivalent.
    \begin{enumerate}[label=(\alph*)]
      \item $T$ is injective.
      \item $T$ takes linearly independent sets in $V$ to linearly independent sets in $W$.
      \item $\ker(T) = \set{0}$.
      \item $\dim(\ker(T)) = 0$.
    \end{enumerate}
  \end{theorem}
  \begin{theorem}{Isomorphism Theorem}
    Suppose that $V$ and $W$ are finite-dimensional vector spaces over $F$ with $\dim(V) = \dim(W)$. Let $T\colon V\to W$ be a linear transformation. Then the following are equivalent.
    \begin{enumerate}[label=(\alph*)]
      \item $T$ is an isomorphism.
      \item $T$ is a monomorphism.
      \item $T$ is an epimorphism.
      \item If $\mathcal{B} = \set{v_1, \dotsc, v_n}$ is a basis for $V$, then $\set{Tv_1, \dotsc,Tv_n}$ is a basis for $W$.
      \item There exists a basis $\mathcal{B}$ of $V$ that maps to a basis of $W$.
    \end{enumerate}
  \end{theorem}
  \begin{theorem}{Universal Property of Vector Spaces}
    Let $V$ be a finite-dimensional vector space over $F$, and let $\mathcal{B} = \set{v_1, \dotsc,v_n}$ be a basis for $V$. Let $W$ be a vector space over $F$, and let $w_1,\dotsc,w_n\in W$ (not necessarily distinct). Then there exists a unique linear transformation $T$ with $T\colon v_i\mapsto w_i$.
  \end{theorem}
  \begin{theorem}{Classification of Finite Dimensional Vector Spaces}
    Let $V$ and $W$ be finite-dimensional vector spaces over the field $F$. Then $V\cong W$ if and only if $\dim(V) = \dim(W)$.
  \end{theorem}
  \begin{theorem}{Matrix Theory Theorem (MTT)}
    Let $V$ and $W$ be finite-dimensional vector spaces of dimesnion $n$ and $m$ over $F$ respectively, and let $\mathcal{B}$ and $\mathcal{C}$ be ordered bases for $V$ and $W$. Then the map
    \begin{align*}
      \varphi\colon L(V, W)&\to F^{m\times n} \\
      T &\mapsto [T]_{\mathcal{B},\mathcal{C}}
    \end{align*}
    is an isomorphism. In particular, $\dim(L(V,W)) = mn$.
  \end{theorem}
  \begin{proof}
    Note that because the zero map is linear, it is in $L(V,W)$ and thus $L(V,W)$ is non-empty. We claim that $\varphi$ is linear. Let $\mathcal{B}=(v_1,\dotsc,v_n)$ and $\mathcal{C}=(w_1,\dotsc,w_m)$ be ordered bases for $V$ and $W$, respectively. Let $T_1, T_2$ be linear maps from $V$ to $W$, and $\alpha\in F$. Let the element in the $i$th row and $j$th column of $\varphi(\alpha T_1 + T_2)$ be $\lam_{i,j}$, the element in the $i$th row and $j$th column of $\varphi(T_1)$ be $\eta_{i,j}$, and the element in the $i$th row and $j$th column of $\varphi(T_2)$ be $\eps_{i,j}$. Then 
    \begin{align*}
      (\alpha T_1 + T_2)v_j &= \lam_{1,j}w_1 + \dotsb + \lam_{m,j}w_m \\
      T_1v_j &= \eta_{1,j}w_1 + \dotsb + \eta_{m,j}w_m \\
      T_2v_j &= \eps_{1,j}w_1 + \dotsb + \eps_{m,j}w_m. \\
      \intertext{From these three equations, we have}
      \lam_{1,j}w_1 + \dotsb + \lam_{m,j}w_m &= (\alpha T_1 + T_2)v_j \\
      &= \alpha T_1v_j + T_2v_j \\
      &= \alpha (\eta_{1,j}w_1 + \dotsb + \eta_{m,j}w_m) + \eps_{1,j}w_1 + \dotsb + \eps_{m,j}w_m \\
      &= (\alpha \eta_{1, j} + \eps_{1, j})w_1 + \dotsb + (\alpha \eta_{m, j} + \eps_{m, j})w_m.
    \end{align*}
    Because $(w_1,\dotsc,w_m)$ is an ordered basis for $W$, and every vector has a unique representation according to any given basis, we have that $\lam_{i,j} = \alpha\eta_{i,j} + \eps_{i,j}$ for all $1\leq i\leq m$ and $1\leq j\leq n$. Thus $\varphi(\alpha T_1 + T_2) = \alpha \varphi(T_1) + \varphi(T_2)$ and $\varphi$ is linear. \par
    We will now show that $\varphi$ is a bijection, first showing that it is injective. Suppose $\varphi(T) = 0$. Then $T(v_i) = 0$ for all $v_i\in \mathcal{B}$, so $Tv = 0$ for all $v\in V$. Thus $T$ is the zero transformation and $\ker(\varphi) = 0$. Therefore $\varphi$ is injective. We will now show that $\varphi$ is surjective. For every matrix in $F^{m\times n}$, consider mapping $v_i\in \mathcal{B}$ to the $i$th column of the matrix. Thus for ever matrix in $F^{m\times n}$, we have a linear transformation that maps to it, so $\varphi$ is surjective. Therefore $\varphi$ is a bijection and so an isomorphism.
  \end{proof}
  \begin{theorem}{12.2}
    Let $V$, $W$, $U$ be finite-dimensional vector spaces over $F$ with ordered bases $\mathcal{B}$, $\mathcal{C}$, $\mathcal{D}$ respectively. If $T\colon V\to W$ and $S\colon W\to U$ are linear, then
    \[
      [S\circ T]_{\mathcal{B}, \mathcal{D}} = [S]_{\mathcal{C},\mathcal{D}}\cdot [T]_{\mathcal{B},\mathcal{C}}.
    \]
  \end{theorem}
  \begin{theorem}{Change of Basis Theorem}
    Let $V$ and $W$ be finite-dimensional vector spaces over $F$ with ordered bases $\mathcal{B}, \mathcal{B}'$ for $V$ and $\mathcal{C}$, $\mathcal{C}'$ for $W$. Let $T\colon V\to W$ be linear. Then
    \begin{align*}
      [T]_{\mathcal{B},\mathcal{C}} &= [1_W]_{\mathcal{C}',\mathcal{C}}[T]_{\mathcal{B}',\mathcal{C}'}[1_V]_{\mathcal{B},\mathcal{B}'} \\
      &= [1_W]_{\mathcal{C},\mathcal{C}'}\inv[T]_{\mathcal{B}',\mathcal{C}'}[1_V]_{\mathcal{B},\mathcal{B}'} \\
      &= [1_W]_{\mathcal{C}',\mathcal{C}}[T]_{\mathcal{B}',\mathcal{C}'}[1_V]_{\mathcal{B}',\mathcal{B}}\inv
    \end{align*}
  \end{theorem}
\end{document}
